{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNISTDemo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "XyuCyUE4wpOW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tensorflow demo to train a neural network to classify digits"
      ]
    },
    {
      "metadata": {
        "id": "3h90Pfoku4F2",
        "colab_type": "code",
        "outputId": "32e39cd3-5275-4507-dbf9-666fe09b646e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "m = x_train.shape[0] # m is the total number of samples\n",
        "\n",
        "print(\"m = \" + str(m))\n",
        "\n",
        "print(\"Shape of training data x_train: \" + str(x_train.shape) + \" y_train : \" + str(y_train.shape))\n",
        "print(\"Shape of test data : \" + str(x_test.shape))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m = 60000\n",
            "Shape of training data x_train: (60000, 28, 28) y_train : (60000,)\n",
            "Shape of test data : (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TJI_Xxzsw2a3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Print some random digits"
      ]
    },
    {
      "metadata": {
        "id": "-8PS1hkjv_UG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "6105aeaf-fa7e-4f51-b6d9-95c07bbc75f7"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "digit_index = 729\n",
        "some_digit = x_train[digit_index]\n",
        "\n",
        "plt.imshow(some_digit, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
        "#plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Y Label : \" + str(y_train[digit_index]))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f53c8b62fd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Y Label : 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xPsivn9C9ytg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Flatten the 2D images to 1D array"
      ]
    },
    {
      "metadata": {
        "id": "SPPKUvC-2WY5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4a9bef51-fc31-4b3a-da8e-21b65e5e3f21"
      },
      "cell_type": "code",
      "source": [
        "# Flatten the images from 2D to 1D\n",
        "X_train_flatten = x_train.reshape(x_train.shape[0], -1).T\n",
        "X_test_flatten = x_test.reshape(x_test.shape[0], -1).T\n",
        "print(\"X_train_flatten shape = \" + str(X_train_flatten.shape))\n",
        "print(\"X_test_flatten shape = \" + str(X_test_flatten.shape))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_flatten shape = (784, 60000)\n",
            "X_test_flatten shape = (784, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5b-PMt5Awn1n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert class label y to one hot vectors"
      ]
    },
    {
      "metadata": {
        "id": "r8gBexZu4CG1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convert each label to a vector of total_classes where only one index that corresponds to the label is one.\n",
        "# Each label vector is a column vector\n",
        "def one_hot_matrix(labels):\n",
        "    \n",
        "    # There are total 10 digits, thus, C that corresponds to total number of classes is 10\n",
        "    C = tf.constant(10, name=\"C\")\n",
        "    one_hot_matrix = tf.one_hot(indices=labels, depth=C, axis=0)\n",
        "    \n",
        "    sess = tf.Session()\n",
        "    one_hot = sess.run(one_hot_matrix) \n",
        "    sess.close()\n",
        "\n",
        "    return one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vND2xVzr4Rnd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "63f46a21-43ae-449c-8d29-8f72481dc3c7"
      },
      "cell_type": "code",
      "source": [
        "# Convert y-labels to 1 hot representation\n",
        "\n",
        "y_train_onehot = one_hot_matrix(y_train)\n",
        "y_test_onehot = one_hot_matrix(y_test)\n",
        "\n",
        "print(\"Shape of y_train_onehot : \" + str(y_train_onehot.shape))\n",
        "print(\"Shape of y_test_onehot : \" + str(y_test_onehot.shape))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of y_train_onehot : (10, 60000)\n",
            "Shape of y_test_onehot : (10, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BOJ3A7GT2qOB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_placeholders(n_x, n_y):\n",
        "    \"\"\"\n",
        "    Creates the placeholders for the tensorflow session.\n",
        "    \n",
        "    Arguments:\n",
        "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 = 784)\n",
        "    n_y -- scalar, number of classes (from 0 to 9, so -> 10)\n",
        "    \n",
        "    Returns:\n",
        "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
        "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
        "    \n",
        "    Tips:\n",
        "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
        "      In fact, the number of examples during test/train is different.\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ### (approx. 2 lines)\n",
        "    X = tf.placeholder(tf.float32, shape = (n_x, None))\n",
        "    Y = tf.placeholder(tf.float32, shape = (n_y, None))\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMDgdFSywDs_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initializes the parameters for the Neural network\n",
        "# The neural network has 2 hidden layers with 25 nodes in the first layer and 12 nodes in the second layer\n",
        "# The output layer has 10 nodes corresponding to the 10 output classes\n",
        "def initialize_parameters():\n",
        "    \n",
        "    tf.set_random_seed(7)\n",
        "    \n",
        "    W1 = tf.get_variable(\"W1\", shape=[25, 784], initializer = tf.contrib.layers.xavier_initializer())\n",
        "    b1 = tf.get_variable(\"b1\", [25, 1], initializer=tf.zeros_initializer())\n",
        "    W2 = tf.get_variable(\"W2\", [12, 25], initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n",
        "    b2 = tf.get_variable(\"b2\", [12, 1], initializer=tf.zeros_initializer())\n",
        "    W3 = tf.get_variable(\"W3\", [10, 12], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
        "    b3 = tf.get_variable(\"b3\", [10,1], initializer = tf.zeros_initializer())\n",
        "    \n",
        "    parameters = {\n",
        "        \"W1\": W1,\n",
        "        \"b1\": b1,\n",
        "        \"W2\": W2,\n",
        "        \"b2\": b2,\n",
        "        \"W3\": W3,\n",
        "        \"b3\": b3\n",
        "    }\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vCv5EZuIxzvS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Predict against a random sample"
      ]
    },
    {
      "metadata": {
        "id": "c2o_dJaCvEDj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Implements the forward propagation in the neural network.\n",
        "# For the 2 hidden layers, RELU is the activation function.\n",
        "# For the output layer, there's no activation function. \n",
        "# Actually, there's sigmoid function, but taken care of in the cost calculation\n",
        "def forward_propagation(X, parameters):\n",
        "    \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "    \n",
        "    Z1 = tf.add(tf.matmul(W1, X), b1)\n",
        "    A1 = tf.nn.relu(Z1)\n",
        "    Z2 = tf.add(tf.matmul(W2, Z1), b2)\n",
        "    A2 = tf.nn.relu(Z2)\n",
        "    Z3 = tf.add(tf.matmul(W3, Z2), b3)\n",
        "    \n",
        "    return Z3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HHvg2wCkvAZk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For the output layer, we use softmax activation function and calculate the overall cost.\n",
        "# Z3 is the output from the last hidden layer\n",
        "# Y is the \"true\" labels vector placeholder\n",
        "def calculate_cost(Z3, Y):\n",
        "    \n",
        "    # Tensorflow expects the shape to be (num_examples, num_classes)\n",
        "    # Hence, we need to transpose these two\n",
        "    labels = tf.transpose(Y) # These correspond to y\n",
        "    logits = tf.transpose(Z3) # These correspond to Z\n",
        "    \n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fNsamSWG61OI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e47fa3a-a17f-46fe-b3a3-15ff020583a5"
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    X, Y = create_placeholders(784, 10)\n",
        "    parameters = initialize_parameters()\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    cost = calculate_cost(Z3, Y)\n",
        "    print(\"cost = \" + str(cost))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iqMLhnk-75LL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (input size, number of examples)\n",
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
        "    mini_batch_size - size of the mini-batches, integer\n",
        "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
        "    \n",
        "    Returns:\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]                  # number of training examples\n",
        "    mini_batches = []\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # Step 1: Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[:, permutation]\n",
        "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
        "\n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    return mini_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jSfnGQXv5PmY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now we build the main neural network using the previously built functions\n",
        "\n",
        "def model(X_train, Y_train, X_test, Y_test, learning_rate=0.0001,\n",
        "         num_epochs = 200, minibatch_size=32, print_cost=True):\n",
        "    \n",
        "    ops.reset_default_graph()\n",
        "    \n",
        "    tf.set_random_seed(7)\n",
        "    seed = 3\n",
        "    (n_x, m) = X_train.shape # Get the number of features and training samples\n",
        "    n_y = Y_train.shape[0]\n",
        "    \n",
        "    costs = [] # To keep track of the costs\n",
        "    \n",
        "    # Create placeholders for X and Y\n",
        "    X, Y = create_placeholders(n_x, n_y)\n",
        "    \n",
        "    # Initialize the W and b parameters for all the layers\n",
        "    parameters = initialize_parameters()\n",
        "    \n",
        "    # Forward propagation\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    \n",
        "    # Calcualte the cost in forward propagation\n",
        "    cost = calculate_cost(Z3, Y)\n",
        "    \n",
        "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
        "    \n",
        "    # Initialize all the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "    \n",
        "    # Start the tensorflow session\n",
        "    with tf.Session() as sess:\n",
        "        \n",
        "        # Run the initialization\n",
        "        sess.run(init)\n",
        "        \n",
        "        for epoch in range(num_epochs):\n",
        "            \n",
        "            epoch_cost = 0\n",
        "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
        "            seed = seed + 1\n",
        "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
        "\n",
        "            for minibatch in minibatches:\n",
        "\n",
        "                # Select a minibatch\n",
        "                (minibatch_X, minibatch_Y) = minibatch\n",
        "                \n",
        "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
        "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
        "                ### START CODE HERE ### (1 line)\n",
        "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
        "                ### END CODE HERE ###\n",
        "                \n",
        "                epoch_cost += minibatch_cost / num_minibatches\n",
        "\n",
        "            # Print the cost every epoch\n",
        "            if print_cost == True and epoch % 100 == 0:\n",
        "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "            if print_cost == True and epoch % 5 == 0:\n",
        "                costs.append(epoch_cost)\n",
        "                \n",
        "        # plot the cost\n",
        "        plt.plot(np.squeeze(costs))\n",
        "        plt.ylabel('cost')\n",
        "        plt.xlabel('iterations (per tens)')\n",
        "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "        plt.show()\n",
        "\n",
        "        # lets save the parameters in a variable\n",
        "        parameters = sess.run(parameters)\n",
        "        print (\"Parameters have been trained!\")\n",
        "\n",
        "        # Calculate the correct predictions\n",
        "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
        "\n",
        "        # Calculate accuracy on the test set\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
        "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
        "        \n",
        "        return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xSkt4ePA5cvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "85f6ab84-3316-4774-e6ea-b94067a6ec09"
      },
      "cell_type": "code",
      "source": [
        "parameters = model(X_train_flatten, y_train_onehot, X_test_flatten, y_test_onehot)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after epoch 0: 0.914693\n",
            "Cost after epoch 100: 0.226118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noRQAIiIJpQAQEUkoBYCISEL9fwSgomuyOb4/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f53c6efa0b8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameters have been trained!\n",
            "Train Accuracy: 0.94088334\n",
            "Test Accuracy: 0.9266\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}